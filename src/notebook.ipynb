{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from -r notebook_requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: pandas in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from -r notebook_requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: nltk in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from -r notebook_requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: matplotlib in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from -r notebook_requirements.txt (line 4)) (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from pandas->-r notebook_requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from pandas->-r notebook_requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from pandas->-r notebook_requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: click in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from nltk->-r notebook_requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from nltk->-r notebook_requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from nltk->-r notebook_requirements.txt (line 3)) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from nltk->-r notebook_requirements.txt (line 3)) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from matplotlib->-r notebook_requirements.txt (line 4)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from matplotlib->-r notebook_requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from matplotlib->-r notebook_requirements.txt (line 4)) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from matplotlib->-r notebook_requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from matplotlib->-r notebook_requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from matplotlib->-r notebook_requirements.txt (line 4)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from matplotlib->-r notebook_requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hugodemenez/Git/textual-analysis/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r notebook_requirements.txt (line 2)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r notebook_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#For Preprocessing\n",
    "import re    # RegEx for removing non-letter characters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  À partir du script ci-dessous, nous avons pu obtenir les recents tweets avec le #BITCOIN en anglais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créons un algorithme pour récupérer les récents tweets avec le hashtag bitcoin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'API twitter étant payante, nous avons du créer un compte et simuler le chargement de la recherche à partir du navigateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_twitter():\n",
    "    import http.client\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    conn = http.client.HTTPSConnection(\"twitter.com\")\n",
    "\n",
    "    headers = {\n",
    "        'cookie': \"des_opt_in=N; d_prefs=MjoxLGNvbnNlbnRfdmVyc2lvbjoyLHRleHRfdmVyc2lvbjoxMDAw; g_state=%7B%22i_p%22%3A1683828026348%2C%22i_l%22%3A1%7D; guest_id=v1%253A168382082645353816; _twitter_sess=BAh7BiIKZmxhc2hJQzonQWN0aW9uQ29udHJvbGxlcjo6Rmxhc2g6OkZsYXNo%25250ASGFzaHsABjoKQHVzZWR7AA%25253D%25253D--1164b91ac812d853b877e93ddb612b7471bebc74; kdt=7iW3OonvnZZrplohikZMqNcWdZgtGsFePCNqo9IC; auth_token=251d0278df8c7e41779f0269c79ae6c197f857d8; ct0=8e4fcb6328b604f7b95e629a4da02567e87db82f0b94ad331c4ecaf797942aea230b17d0c71bad6c51827094c11dcd2f5f45425dabdd42a24a795c0e18c90edb756723ffa0ccbed6f1b8443c79a0941e; lang=en; twid=u%253D1656691580143583236\",\n",
    "        'authority': \"twitter.com\",\n",
    "        'accept': \"*/*\",\n",
    "        'accept-language': \"en,fr;q=0.9\",\n",
    "        'authorization': f\"Bearer {os.getenv('BEARER_TOKEN')}\",\n",
    "        'dnt': \"1\",\n",
    "        'referer': \"https://twitter.com/search?q=-giving%20-givaway%20-give%20-win%20(%23bitcoin)%20min_faves%3A1000%20min_retweets%3A100%20lang%3Aen%20-filter%3Alinks%20-filter%3Areplies&src=typed_query\",\n",
    "        'sec-ch-ua': '\"Chromium\";v=\"113\", \"Not-A.Brand\";v=\"24\"',\n",
    "        'sec-ch-ua-mobile': \"?0\",\n",
    "        'sec-ch-ua-platform': '\"macOS\"',\n",
    "        'sec-fetch-dest': \"empty\",\n",
    "        'sec-fetch-mode': \"cors\",\n",
    "        'sec-fetch-site': \"same-origin\",\n",
    "        'user-agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\",\n",
    "        'x-client-uuid': \"d4a81861-d1b3-4ea5-83b4-c32a71a3ea90\",\n",
    "        'x-csrf-token': \"8e4fcb6328b604f7b95e629a4da02567e87db82f0b94ad331c4ecaf797942aea230b17d0c71bad6c51827094c11dcd2f5f45425dabdd42a24a795c0e18c90edb756723ffa0ccbed6f1b8443c79a0941e\",\n",
    "        'x-twitter-active-user': \"yes\",\n",
    "        'x-twitter-auth-type': \"OAuth2Session\",\n",
    "        'x-twitter-client-language': \"en\"\n",
    "        }\n",
    "\n",
    "    # Specific endpoint specifying : \n",
    "    # #bitcoin, \n",
    "    # 1000 minimum likes,\n",
    "    # 100 minimum retweets,\n",
    "    # not including (give, givaway, win, giving)\n",
    "    conn.request(\"GET\", \"/i/api/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&include_ext_has_nft_avatar=1&include_ext_is_blue_verified=1&include_ext_verified_type=1&include_ext_profile_image_shape=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_ext_limited_action_results=false&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_ext_views=true&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&include_ext_sensitive_media_warning=true&include_ext_trusted_friends_metadata=true&send_error_codes=true&simple_quoted_tweet=true&q=-giving%20-givaway%20-give%20-win%20(%23bitcoin)%20min_faves%3A1000%20min_retweets%3A100%20lang%3Aen%20-filter%3Alinks%20-filter%3Areplies&query_source=typed_query&count=20&requestContext=launch&pc=1&spelling_corrections=1&include_ext_edit_control=true&ext=mediaStats%2ChighlightedLabel%2ChasNftAvatar%2CvoiceInfo%2CbirdwatchPivot%2Cenrichments%2CsuperFollowMetadata%2CunmentionInfo%2CeditControl%2Cvibe\", headers=headers)\n",
    "\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    return data.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_twitter_response(response):\n",
    "    import json\n",
    "    response = json.loads(response)\n",
    "    return [\n",
    "        {\n",
    "            'text': response['globalObjects']['tweets'][tweet_id]['full_text'],\n",
    "            'date': response['globalObjects']['tweets'][tweet_id]['created_at'],\n",
    "        } \n",
    "        for tweet_id in response['globalObjects']['tweets']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_new_tweets(tweets):\n",
    "    # Check if the fetched tweets are new\n",
    "    # Load history tweets\n",
    "    try:\n",
    "        with open('new_tweets.json', 'r') as f:\n",
    "            loaded_tweets = json.load(f)\n",
    "            # Compare the new tweets with the previous ones\n",
    "    except FileNotFoundError:\n",
    "        print('First time fetching tweets')\n",
    "    \n",
    "    # Write new tweets to new_tweets.json\n",
    "    with open('new_tweets.json', 'w',encoding='utf-8') as f:\n",
    "        json.dump(tweets, f)\n",
    "\n",
    "    # Load history tweets\n",
    "    try:\n",
    "        with open('history_tweets.json', 'r') as f:\n",
    "            loaded_tweets = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print('No history file found')\n",
    "\n",
    "    # Merge new tweets with history tweets\n",
    "    with open('history_tweets.json', 'w',encoding='utf-8') as f:\n",
    "        json.dump(tweets + loaded_tweets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = parse_twitter_response(fetch_twitter())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargeons le dictionnaire de Loughran et McDonald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Seq_num</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong_Modal</th>\n",
       "      <th>Weak_Modal</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>1.550080e-08</td>\n",
       "      <td>1.422600e-08</td>\n",
       "      <td>3.815486e-06</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.313627e-10</td>\n",
       "      <td>8.653817e-12</td>\n",
       "      <td>9.241714e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.940882e-10</td>\n",
       "      <td>1.169679e-10</td>\n",
       "      <td>5.290465e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.269840e-09</td>\n",
       "      <td>6.654735e-10</td>\n",
       "      <td>1.595100e-07</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>8570</td>\n",
       "      <td>3.752595e-07</td>\n",
       "      <td>3.809464e-07</td>\n",
       "      <td>3.529356e-05</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86526</th>\n",
       "      <td>ZYGOTE</td>\n",
       "      <td>86529</td>\n",
       "      <td>50</td>\n",
       "      <td>2.189379e-09</td>\n",
       "      <td>8.729336e-10</td>\n",
       "      <td>1.886011e-07</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86527</th>\n",
       "      <td>ZYGOTES</td>\n",
       "      <td>86530</td>\n",
       "      <td>1</td>\n",
       "      <td>4.378757e-11</td>\n",
       "      <td>1.809516e-11</td>\n",
       "      <td>1.932446e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86528</th>\n",
       "      <td>ZYGOTIC</td>\n",
       "      <td>86531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86529</th>\n",
       "      <td>ZYMURGIES</td>\n",
       "      <td>86532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86530</th>\n",
       "      <td>ZYMURGY</td>\n",
       "      <td>86533</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86531 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Seq_num  Word Count  Word Proportion  Average Proportion   \n",
       "0       AARDVARK        1         354     1.550080e-08        1.422600e-08  \\\n",
       "1      AARDVARKS        2           3     1.313627e-10        8.653817e-12   \n",
       "2          ABACI        3           9     3.940882e-10        1.169679e-10   \n",
       "3          ABACK        4          29     1.269840e-09        6.654735e-10   \n",
       "4         ABACUS        5        8570     3.752595e-07        3.809464e-07   \n",
       "...          ...      ...         ...              ...                 ...   \n",
       "86526     ZYGOTE    86529          50     2.189379e-09        8.729336e-10   \n",
       "86527    ZYGOTES    86530           1     4.378757e-11        1.809516e-11   \n",
       "86528    ZYGOTIC    86531           0     0.000000e+00        0.000000e+00   \n",
       "86529  ZYMURGIES    86532           0     0.000000e+00        0.000000e+00   \n",
       "86530    ZYMURGY    86533           0     0.000000e+00        0.000000e+00   \n",
       "\n",
       "            Std Dev  Doc Count  Negative  Positive  Uncertainty  Litigious   \n",
       "0      3.815486e-06         99         0         0            0          0  \\\n",
       "1      9.241714e-09          1         0         0            0          0   \n",
       "2      5.290465e-08          7         0         0            0          0   \n",
       "3      1.595100e-07         28         0         0            0          0   \n",
       "4      3.529356e-05       1108         0         0            0          0   \n",
       "...             ...        ...       ...       ...          ...        ...   \n",
       "86526  1.886011e-07         35         0         0            0          0   \n",
       "86527  1.932446e-08          1         0         0            0          0   \n",
       "86528  0.000000e+00          0         0         0            0          0   \n",
       "86529  0.000000e+00          0         0         0            0          0   \n",
       "86530  0.000000e+00          0         0         0            0          0   \n",
       "\n",
       "       Strong_Modal  Weak_Modal  Constraining  Syllables     Source  \n",
       "0                 0           0             0          2  12of12inf  \n",
       "1                 0           0             0          2  12of12inf  \n",
       "2                 0           0             0          3  12of12inf  \n",
       "3                 0           0             0          2  12of12inf  \n",
       "4                 0           0             0          3  12of12inf  \n",
       "...             ...         ...           ...        ...        ...  \n",
       "86526             0           0             0          2  12of12inf  \n",
       "86527             0           0             0          2  12of12inf  \n",
       "86528             0           0             0          3  12of12inf  \n",
       "86529             0           0             0          3  12of12inf  \n",
       "86530             0           0             0          3  12of12inf  \n",
       "\n",
       "[86531 rows x 16 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOUGHRAN_MCDONALD_DATASET = pd.read_csv('./dataset/Loughran-McDonald_MasterDictionary_1993-2021.csv')\n",
    "LOUGHRAN_MCDONALD_DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'JUST IN BITCOIN MINER MARATHON PARTNERS WITH ZERO TWO BACKED BY ABU DHABIS 853 BILLION SOVEREIGN WEALTH FUND TO CREATE THE MIDDLE EASTS FIRST LARGE SCALE IMMERSION BTC MINING OPERATION ', 'date': 'Tue May 09 21:09:43 +0000 2023'}, {'text': 'FUN FACT 11 YEARS AGO TODAY THE BITCOIN PRICE WAS 502 ', 'date': 'Mon May 08 20:50:11 +0000 2023'}, {'text': 'MONG IS THE NEXT BITCOIN', 'date': 'Sat May 13 00:17:16 +0000 2023'}, {'text': ' BITCOIN HALTED ETHEREUM FEES TOO EXPENSIVE PULSECHAIN MAINNET LAUNCH', 'date': 'Wed May 10 12:47:32 +0000 2023'}, {'text': 'JUST IN  JUDGE RULES THAT BLOCKFI USERS GAVE UP LEGAL RIGHTS TO THEIR BTC BY USING THE PLATFORM AND ALL THE 300 MILLION OF CRYPTO DEPOSITS ARE NOW PROPERTY OF BLOCKFITAKE YOUR BITCOIN OFF EXCHANGES', 'date': 'Thu May 11 17:03:41 +0000 2023'}, {'text': 'IT REALLY HURTS MY FEELINGS THAT PEOPLE ARE BUYING BITCOIN AND WITHDRAWING MONEY FROM BANKSWHAT IS WRONG WITH PEOPLEI TRUST GARY GENSLER ELIZABETH WARREN NANCY PELOSI AND ALL OF THEMTHEY CARE ABOUT USBITCOIN ISNT EVEN BACKED BY THE GOVERNMENTTHE', 'date': 'Wed May 03 21:33:18 +0000 2023'}, {'text': 'JUST IN BINANCE TO INTEGRATE BITCOINLIGHTNING NETWORK', 'date': 'Mon May 08 04:28:25 +0000 2023'}, {'text': 'BREAKING THE STATE OF MONTANA SIGNS INTO LAW A BILL PROHIBITING ANY TAXATION ON THE USE OF BITCOIN AS PAYMENT', 'date': 'Fri May 05 01:39:50 +0000 2023'}, {'text': 'CPI DATA IS COMING TOMORROW EXPECTED IS 5 ONE PERSON WHO PREDICTS THE RIGHT ANSWER WILL GET 100 BITCOIN DROP YOUR PREDICTION BELOW ', 'date': 'Wed May 10 05:28:50 +0000 2023'}, {'text': '94 OF BITCOINHOLDERS ARE UNDER 40 YEARS OLD WE ARE GOING TO SEE THE LARGEST WEALTH FLIPPING IN HISTORY', 'date': 'Tue May 09 10:07:36 +0000 2023'}, {'text': ' TODAY A US CONGRESSMAN PUBLICLY ADMITTED THEY PRINT MONEY OUT OF THIN AIR BUT ITS OK SINCE THEYRE THE GOVERNMENTBUY BITCOIN', 'date': 'Wed May 10 20:57:45 +0000 2023'}, {'text': 'BREAKING OG BITCOIN EXCHANGE BITTREX FILES FOR BANKRUPTCY', 'date': 'Mon May 08 21:11:08 +0000 2023'}, {'text': 'ACQUIRING AN ENTIRE BITCOIN WILL SOON BE UNATTAINABLE FOR MOST', 'date': 'Wed May 10 12:42:23 +0000 2023'}, {'text': 'IM LAUNCHING A BITCOIN BRC20 TOKEN AT THE END OF THIS WEEKHERES WHAT THIS MEANS ', 'date': 'Sun May 07 16:29:34 +0000 2023'}, {'text': 'WENT TO BUY A 3 CUP OF COFFEE USING BITCOIN  ENDED UP PAYING 78 WITH FEES AMP HAD TO WAIT 6 HOURS FOR THE TRANSACTION TO GO THROUGHTHE FUTURE OF FINANCE  ', 'date': 'Wed May 10 04:08:23 +0000 2023'}, {'text': 'NEW  BANKING CRISIS HAS RESTORED FAITH IN BITCOIN AFTER BRUTAL BEAR MARKET  FORBES', 'date': 'Thu May 04 13:32:30 +0000 2023'}, {'text': 'WHICH FAMOUS BOXER BECAME AN ENTREPRENEUR AND ACCEPTED PAYMENTS IN BITCOIN BY INSTALLING BITCOIN ATMS', 'date': 'Sun May 07 14:16:49 +0000 2023'}, {'text': 'NEW   US PRESIDENTIAL CANDIDATE ROBERT KENNEDY JR SAYS WE NEED BITCOIN TO ENSURE FREEDOM ', 'date': 'Wed May 03 20:08:12 +0000 2023'}, {'text': 'NEW  TEXAS VOTES TO ADD THE RIGHT TO USE BITCOIN INTO STATES BILL OF RIGHTS ', 'date': 'Fri May 12 11:30:39 +0000 2023'}]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_cleaning(data : dict) -> list:\n",
    "    \"\"\" Nous devons nettoyer le dataset pour ne garder que les mots qui nous intéressent\n",
    "    Pour cela nous utilisons les stop words qui sont définis dans le fichier StopWords_Generix.txt\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    with open('./dataset/StopWords_Generic.txt', 'r') as f:\n",
    "        stop_words = f.read().split('\\n')\n",
    "    for element in data:\n",
    "        for (header,content) in element.items():\n",
    "            if header == 'text':\n",
    "                modified = ' '.join([(''.join(letter.upper() for letter in word if letter.isalnum())) for word in content.split(' ')])\n",
    "            else:\n",
    "                date = content\n",
    "        result.append( {\n",
    "            'text': modified,\n",
    "            'date':date\n",
    "        })\n",
    "    return result\n",
    "\n",
    "data_cleaning(tweets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintenant que le dictionnaire est chargé, nous pouvons créer notre algorithme pour calculer un score : positif ou negatif pour chaque texte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
